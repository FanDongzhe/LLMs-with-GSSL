Namespace(batch_size=1024, dataset='arxiv', decode_channels=256, decode_layers=3, device=0, dropout=0.5, epochs=400, eval_steps=1, feature_type='TA', hidden_channels=128, log_steps=1, lr=0.001, mask_ratio=0.8, mask_type='dm', num_layers=2, patience=50, runs=3, seed=42, use_sage='GCN', use_valedges_as_input=False)
loading ogb dataset...
Loading pretrained LM features (title and abstract) ...
LM_emb_path: ../prt_lm/ogbn-arxiv/microsoft/deberta-base-seed0.emb
### Input graph arxiv is directed
Start training with mask ratio=0.8 # optimization edges=833616 / 1042020
Run: 01, Epoch: 01, Best_epoch: 01, Best_valid: 99.48%, Loss: 0.4098, 
***************
Run: 01, Epoch: 02, Best_epoch: 02, Best_valid: 99.61%, Loss: 0.3385, 
***************
Run: 01, Epoch: 03, Best_epoch: 03, Best_valid: 99.64%, Loss: 0.3223, 
***************
Run: 01, Epoch: 04, Best_epoch: 04, Best_valid: 99.67%, Loss: 0.3117, 
***************
Run: 01, Epoch: 05, Best_epoch: 05, Best_valid: 99.69%, Loss: 0.3063, 
***************
Run: 01, Epoch: 06, Best_epoch: 06, Best_valid: 99.69%, Loss: 0.3022, 
***************
Run: 01, Epoch: 07, Best_epoch: 07, Best_valid: 99.72%, Loss: 0.2964, 
***************
Run: 01, Epoch: 08, Best_epoch: 08, Best_valid: 99.72%, Loss: 0.2960, 
***************
Run: 01, Epoch: 09, Best_epoch: 09, Best_valid: 99.73%, Loss: 0.2928, 
***************
Run: 01, Epoch: 10, Best_epoch: 10, Best_valid: 99.73%, Loss: 0.2921, 
***************
Run: 01, Epoch: 11, Best_epoch: 10, Best_valid: 99.73%, Loss: 0.2897, 
***************
Run: 01, Epoch: 12, Best_epoch: 12, Best_valid: 99.75%, Loss: 0.2886, 
***************
Run: 01, Epoch: 13, Best_epoch: 12, Best_valid: 99.75%, Loss: 0.2874, 
***************
Run: 01, Epoch: 14, Best_epoch: 14, Best_valid: 99.76%, Loss: 0.2869, 
***************
Run: 01, Epoch: 15, Best_epoch: 14, Best_valid: 99.76%, Loss: 0.2864, 
***************
Run: 01, Epoch: 16, Best_epoch: 16, Best_valid: 99.76%, Loss: 0.2836, 
***************
Run: 01, Epoch: 17, Best_epoch: 17, Best_valid: 99.76%, Loss: 0.2858, 
***************
Run: 01, Epoch: 18, Best_epoch: 18, Best_valid: 99.78%, Loss: 0.2838, 
***************
Run: 01, Epoch: 19, Best_epoch: 18, Best_valid: 99.78%, Loss: 0.2831, 
***************
Run: 01, Epoch: 20, Best_epoch: 18, Best_valid: 99.78%, Loss: 0.2836, 
***************
Run: 01, Epoch: 21, Best_epoch: 21, Best_valid: 99.78%, Loss: 0.2824, 
***************
Run: 01, Epoch: 22, Best_epoch: 21, Best_valid: 99.78%, Loss: 0.2829, 
***************
Run: 01, Epoch: 23, Best_epoch: 21, Best_valid: 99.78%, Loss: 0.2824, 
***************
Run: 01, Epoch: 24, Best_epoch: 21, Best_valid: 99.78%, Loss: 0.2817, 
***************
Run: 01, Epoch: 25, Best_epoch: 25, Best_valid: 99.79%, Loss: 0.2827, 
***************
Run: 01, Epoch: 26, Best_epoch: 25, Best_valid: 99.79%, Loss: 0.2828, 
***************
Run: 01, Epoch: 27, Best_epoch: 25, Best_valid: 99.79%, Loss: 0.2813, 
***************
Run: 01, Epoch: 28, Best_epoch: 25, Best_valid: 99.79%, Loss: 0.2813, 
***************
Run: 01, Epoch: 29, Best_epoch: 29, Best_valid: 99.79%, Loss: 0.2804, 
***************
Run: 01, Epoch: 30, Best_epoch: 30, Best_valid: 99.80%, Loss: 0.2837, 
***************
Run: 01, Epoch: 31, Best_epoch: 30, Best_valid: 99.80%, Loss: 0.2803, 
***************
Run: 01, Epoch: 32, Best_epoch: 30, Best_valid: 99.80%, Loss: 0.2813, 
***************
Run: 01, Epoch: 33, Best_epoch: 33, Best_valid: 99.80%, Loss: 0.2815, 
***************
Run: 01, Epoch: 34, Best_epoch: 33, Best_valid: 99.80%, Loss: 0.2824, 
***************
Run: 01, Epoch: 35, Best_epoch: 33, Best_valid: 99.80%, Loss: 0.2815, 
***************
Run: 01, Epoch: 36, Best_epoch: 33, Best_valid: 99.80%, Loss: 0.2808, 
***************
Run: 01, Epoch: 37, Best_epoch: 33, Best_valid: 99.80%, Loss: 0.2827, 
***************
Run: 01, Epoch: 38, Best_epoch: 33, Best_valid: 99.80%, Loss: 0.2829, 
***************
Run: 01, Epoch: 39, Best_epoch: 33, Best_valid: 99.80%, Loss: 0.2817, 
***************
Run: 01, Epoch: 40, Best_epoch: 40, Best_valid: 99.81%, Loss: 0.2814, 
***************
Run: 01, Epoch: 41, Best_epoch: 40, Best_valid: 99.81%, Loss: 0.2820, 
***************
Run: 01, Epoch: 42, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2833, 
***************
Run: 01, Epoch: 43, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2824, 
***************
Run: 01, Epoch: 44, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2828, 
***************
Run: 01, Epoch: 45, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2829, 
***************
Run: 01, Epoch: 46, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2820, 
***************
Run: 01, Epoch: 47, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2810, 
***************
Run: 01, Epoch: 48, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2827, 
***************
Run: 01, Epoch: 49, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2823, 
***************
Run: 01, Epoch: 50, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2824, 
***************
Run: 01, Epoch: 51, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2821, 
***************
Run: 01, Epoch: 52, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2834, 
***************
Run: 01, Epoch: 53, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2824, 
***************
Run: 01, Epoch: 54, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2809, 
***************
Run: 01, Epoch: 55, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2828, 
***************
Run: 01, Epoch: 56, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2843, 
***************
Run: 01, Epoch: 57, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2837, 
***************
Run: 01, Epoch: 58, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2838, 
***************
Run: 01, Epoch: 59, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2847, 
***************
Run: 01, Epoch: 60, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2847, 
***************
Run: 01, Epoch: 61, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2840, 
***************
Run: 01, Epoch: 62, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2830, 
***************
Run: 01, Epoch: 63, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2848, 
***************
Run: 01, Epoch: 64, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2843, 
***************
Run: 01, Epoch: 65, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2847, 
***************
Run: 01, Epoch: 66, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2841, 
***************
Run: 01, Epoch: 67, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2854, 
***************
Run: 01, Epoch: 68, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2856, 
***************
Run: 01, Epoch: 69, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2840, 
***************
Run: 01, Epoch: 70, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2857, 
***************
Run: 01, Epoch: 71, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2845, 
***************
Run: 01, Epoch: 72, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2855, 
***************
Run: 01, Epoch: 73, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2844, 
***************
Run: 01, Epoch: 74, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2846, 
***************
Run: 01, Epoch: 75, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2853, 
***************
Run: 01, Epoch: 76, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2850, 
***************
Run: 01, Epoch: 77, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2852, 
***************
Run: 01, Epoch: 78, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2854, 
***************
Run: 01, Epoch: 79, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2842, 
***************
Run: 01, Epoch: 80, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2847, 
***************
Run: 01, Epoch: 81, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2838, 
***************
Run: 01, Epoch: 82, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2850, 
***************
Run: 01, Epoch: 83, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2854, 
***************
Run: 01, Epoch: 84, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2847, 
***************
Run: 01, Epoch: 85, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2872, 
***************
Run: 01, Epoch: 86, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2858, 
***************
Run: 01, Epoch: 87, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2852, 
***************
Run: 01, Epoch: 88, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2873, 
***************
Run: 01, Epoch: 89, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2863, 
***************
Run: 01, Epoch: 90, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2862, 
***************
Run: 01, Epoch: 91, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2856, 
***************
Run: 01, Epoch: 92, Best_epoch: 42, Best_valid: 99.81%, Loss: 0.2856, 
***************
Early stop at 92
##### Testing on 0/3
Traceback (most recent call last):
  File "s2gae_nc_acc.py", line 394, in <module>
    main()
  File "s2gae_nc_acc.py", line 372, in main
    args.dataset)
  File "../data_utils/logistic_regression_eval.py", line 71, in fit_logistic_regression
    y_train_labels = np.argmax(y_train, axis=1)
  File "<__array_function__ internals>", line 6, in argmax
  File "/mnt/home/tangxiaqiang/miniconda3/envs/graph/lib/python3.7/site-packages/numpy/core/fromnumeric.py", line 1195, in argmax
    return _wrapfunc(a, 'argmax', axis=axis, out=out)
  File "/mnt/home/tangxiaqiang/miniconda3/envs/graph/lib/python3.7/site-packages/numpy/core/fromnumeric.py", line 57, in _wrapfunc
    return bound(*args, **kwds)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1
